{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Algos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Jf6X-aboSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roU43DyPRI69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJBVFhAIbpRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "link = 'https://drive.google.com/open?id=1WK8WZbqvThGM6OUBxtTA7igLjfq4JTNU'\n",
        "fluff,id = link.split('=')\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('final_dataset.csv')  \n",
        "dataset = pd.read_csv('final_dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDFdiOeayjSg",
        "colab_type": "code",
        "outputId": "a88bf26d-9d78-4df9-f933-303174a42765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "dataset.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'ArrDel15', 'ArrDelayMinutes', 'ArrTime', 'CRSArrTime',\n",
              "       'CRSDepTime', 'DayofMonth', 'DepDel15', 'DepDelayMinutes', 'DepTime',\n",
              "       'Dest', 'DestAirportID', 'FlightDate', 'Month', 'Origin',\n",
              "       'OriginAirportID', 'Quarter', 'Year', 'CRSDepTimedup', 'CRSArrTimedup',\n",
              "       'airport_x', 'DewPointF_x', 'windspeedKmph_x', 'precipMM_x',\n",
              "       'WindGustKmph_x', 'tempF_x', 'WindChillF_x', 'winddirDegree_x',\n",
              "       'humidity_x', 'time_x', 'cloudcover_x', 'pressure_x', 'airport_y',\n",
              "       'DewPointF_y', 'windspeedKmph_y', 'precipMM_y', 'WindGustKmph_y',\n",
              "       'tempF_y', 'WindChillF_y', 'winddirDegree_y', 'humidity_y', 'time_y',\n",
              "       'cloudcover_y', 'pressure_y', 'FlightData'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAMULgSCcYqe",
        "colab_type": "text"
      },
      "source": [
        "#Normal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPyTp5KRbqtT",
        "colab_type": "code",
        "outputId": "04e93aca-1e83-4d75-a5da-5c761a6908d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "#Logistic Regression\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "\n",
        "X = dataset.iloc[:,[21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:,7])\n",
        "#splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.4, random_state = 0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_train)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      1.00      0.89    580815\n",
            "         1.0       0.44      0.00      0.01    145346\n",
            "\n",
            "    accuracy                           0.80    726161\n",
            "   macro avg       0.62      0.50      0.45    726161\n",
            "weighted avg       0.73      0.80      0.71    726161\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      1.00      0.89    871590\n",
            "         1.0       0.43      0.00      0.01    217651\n",
            "\n",
            "    accuracy                           0.80   1089241\n",
            "   macro avg       0.62      0.50      0.45   1089241\n",
            "weighted avg       0.73      0.80      0.71   1089241\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbMVG6E7cLCk",
        "colab_type": "code",
        "outputId": "c292d23d-e3db-4cda-bf5f-1e18ad90621f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Random_Forest  depdel15\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "\n",
        "X = dataset.iloc[:, [21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:, 7])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 12)\n",
        "#X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "# Fitting Random Forest Classification to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0, n_jobs = -1)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_train)\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.96      0.90    871206\n",
            "         1.0       0.68      0.32      0.44    218035\n",
            "\n",
            "    accuracy                           0.83   1089241\n",
            "   macro avg       0.77      0.64      0.67   1089241\n",
            "weighted avg       0.82      0.83      0.81   1089241\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.93      0.87    581199\n",
            "         1.0       0.43      0.22      0.29    144962\n",
            "\n",
            "    accuracy                           0.79    726161\n",
            "   macro avg       0.63      0.57      0.58    726161\n",
            "weighted avg       0.75      0.79      0.76    726161\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg-BSa55coR8",
        "colab_type": "code",
        "outputId": "3304d7c9-1b47-4834-852d-d68236109ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2104
        }
      },
      "source": [
        "#Extra trees using depdel15 and oversampling\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "\n",
        "\n",
        "X = dataset.iloc[:, [21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:, 7])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 12)\n",
        "\n",
        "\n",
        "# Feature Scaling\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "#sc = StandardScaler()\n",
        "#X_train1 = sc.fit_transform(X_train1)\n",
        "#X_test = sc.transform(X_test)\n",
        "\n",
        "for i in range(1,11):\n",
        "  print( \"Number of trees \" + str(100+i))\n",
        "  from sklearn.ensemble import ExtraTreesClassifier\n",
        "  extc = ExtraTreesClassifier(n_estimators = 100+i,n_jobs = -1)\n",
        "  extc.fit(X_train,y_train)\n",
        "\n",
        "  y_pred = extc.predict(X_train)\n",
        "  # Making the Confusion Matrix\n",
        "  from sklearn.metrics import confusion_matrix, classification_report\n",
        "  cm = confusion_matrix(y_train, y_pred)\n",
        "  print(classification_report(y_train,y_pred))\n",
        "\n",
        "\n",
        "  y_pred = extc.predict(X_test)\n",
        "  # Making the Confusion Matrix\n",
        "  from sklearn.metrics import confusion_matrix, classification_report\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trees 101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.97      0.90    871206\n",
            "         1.0       0.73      0.28      0.40    218035\n",
            "\n",
            "    accuracy                           0.83   1089241\n",
            "   macro avg       0.79      0.63      0.65   1089241\n",
            "weighted avg       0.82      0.83      0.80   1089241\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.95      0.88    581199\n",
            "         1.0       0.47      0.19      0.27    144962\n",
            "\n",
            "    accuracy                           0.79    726161\n",
            "   macro avg       0.64      0.57      0.57    726161\n",
            "weighted avg       0.75      0.79      0.76    726161\n",
            "\n",
            "Number of trees 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.97      0.90    871206\n",
            "         1.0       0.73      0.28      0.40    218035\n",
            "\n",
            "    accuracy                           0.83   1089241\n",
            "   macro avg       0.79      0.63      0.65   1089241\n",
            "weighted avg       0.82      0.83      0.80   1089241\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.95      0.88    581199\n",
            "         1.0       0.47      0.19      0.27    144962\n",
            "\n",
            "    accuracy                           0.79    726161\n",
            "   macro avg       0.64      0.57      0.57    726161\n",
            "weighted avg       0.75      0.79      0.76    726161\n",
            "\n",
            "Number of trees 103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.97      0.90    871206\n",
            "         1.0       0.73      0.28      0.40    218035\n",
            "\n",
            "    accuracy                           0.83   1089241\n",
            "   macro avg       0.79      0.63      0.65   1089241\n",
            "weighted avg       0.82      0.83      0.80   1089241\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.95      0.88    581199\n",
            "         1.0       0.47      0.19      0.27    144962\n",
            "\n",
            "    accuracy                           0.79    726161\n",
            "   macro avg       0.64      0.57      0.57    726161\n",
            "weighted avg       0.75      0.79      0.76    726161\n",
            "\n",
            "Number of trees 104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.97      0.90    871206\n",
            "         1.0       0.73      0.28      0.40    218035\n",
            "\n",
            "    accuracy                           0.83   1089241\n",
            "   macro avg       0.79      0.63      0.65   1089241\n",
            "weighted avg       0.82      0.83      0.80   1089241\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.95      0.88    581199\n",
            "         1.0       0.47      0.19      0.27    144962\n",
            "\n",
            "    accuracy                           0.79    726161\n",
            "   macro avg       0.64      0.57      0.57    726161\n",
            "weighted avg       0.75      0.79      0.76    726161\n",
            "\n",
            "Number of trees 105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.97      0.90    871206\n",
            "         1.0       0.73      0.28      0.40    218035\n",
            "\n",
            "    accuracy                           0.83   1089241\n",
            "   macro avg       0.79      0.63      0.65   1089241\n",
            "weighted avg       0.82      0.83      0.80   1089241\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.95      0.88    581199\n",
            "         1.0       0.47      0.19      0.27    144962\n",
            "\n",
            "    accuracy                           0.79    726161\n",
            "   macro avg       0.64      0.57      0.57    726161\n",
            "weighted avg       0.75      0.79      0.76    726161\n",
            "\n",
            "Number of trees 106"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7365a04ba748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mextc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mextc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1itIqnhHdbqE",
        "colab_type": "code",
        "outputId": "d865dcd2-98ff-46b7-f9b2-d20449e88c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "# XGBoost on depdel15\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "\n",
        "X = dataset.iloc[:, [21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:, 7])\n",
        "\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4,random_state=0)\n",
        "\n",
        "# Fitting XGBoost to the Training set\n",
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_train)\n",
        "from sklearn.metrics import classification_report\n",
        "print('Training set')\n",
        "print(classification_report(y_pred,y_train))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print('Test set')\n",
        "print(classification_report(y_pred,y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.80      0.89   1087971\n",
            "         1.0       0.00      0.73      0.01      1270\n",
            "\n",
            "    accuracy                           0.80   1089241\n",
            "   macro avg       0.50      0.77      0.45   1089241\n",
            "weighted avg       1.00      0.80      0.89   1089241\n",
            "\n",
            "Test set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.80      0.89    725394\n",
            "         1.0       0.00      0.70      0.01       767\n",
            "\n",
            "    accuracy                           0.80    726161\n",
            "   macro avg       0.50      0.75      0.45    726161\n",
            "weighted avg       1.00      0.80      0.89    726161\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwGeWsYxdm9k",
        "colab_type": "code",
        "outputId": "4112f8b7-32be-46a1-a0a0-8ec2f69f23fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "#Decision Tree\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "X = dataset.iloc[:, [21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:, 7])\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "# Fitting Decision Tree Classification to the Training set\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.95      0.88    363313\n",
            "         1.0       0.49      0.18      0.27     90538\n",
            "\n",
            "    accuracy                           0.80    453851\n",
            "   macro avg       0.66      0.57      0.58    453851\n",
            "weighted avg       0.76      0.80      0.76    453851\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBw7agrreQBF",
        "colab_type": "text"
      },
      "source": [
        "#Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SneadwgdeBZk",
        "colab_type": "code",
        "outputId": "69678067-a46a-4d0a-c2b5-80f5211ed807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Logistic Regression\n",
        "import numpy as np\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "no_frauds = len(dataset[dataset['DepDel15']==1])\n",
        "non_fraud_indices = dataset[dataset.DepDel15 == 0].index\n",
        "random_indices = np.random.choice(non_fraud_indices,no_frauds, replace=False)\n",
        "fraud_indices = dataset[dataset.DepDel15 == 1].index\n",
        "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n",
        "under_sample = dataset.loc[under_sample_indices]\n",
        "dataset = under_sample\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:,[21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:,7])\n",
        "\n",
        "\n",
        "#splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.56      0.60      0.58     90681\n",
            "         1.0       0.57      0.54      0.55     90818\n",
            "\n",
            "    accuracy                           0.57    181499\n",
            "   macro avg       0.57      0.57      0.56    181499\n",
            "weighted avg       0.57      0.57      0.56    181499\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIm3e7qRi4tV",
        "colab_type": "code",
        "outputId": "b19495a8-2216-43df-c90e-b10927143fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Random_Forest  depdel15\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "no_frauds = len(dataset[dataset['DepDel15']==1])\n",
        "non_fraud_indices = dataset[dataset.DepDel15 == 0].index\n",
        "random_indices = np.random.choice(non_fraud_indices,no_frauds, replace=False)\n",
        "fraud_indices = dataset[dataset.DepDel15 == 1].index\n",
        "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n",
        "under_sample = dataset.loc[under_sample_indices]\n",
        "dataset = under_sample\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:, [21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:, 7])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "#X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "print(\"N_estimators = \" + str(100+i))\n",
        "# Fitting Random Forest Classification to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 0, n_jobs = -1)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_train)\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N_estimators = 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.77      0.77      0.77    290209\n",
            "         1.0       0.77      0.77      0.77    290586\n",
            "\n",
            "    accuracy                           0.77    580795\n",
            "   macro avg       0.77      0.77      0.77    580795\n",
            "weighted avg       0.77      0.77      0.77    580795\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.61      0.61     72788\n",
            "         1.0       0.61      0.61      0.61     72411\n",
            "\n",
            "    accuracy                           0.61    145199\n",
            "   macro avg       0.61      0.61      0.61    145199\n",
            "weighted avg       0.61      0.61      0.61    145199\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiQ2XiPgji6N",
        "colab_type": "code",
        "outputId": "bc1da11d-aa9d-4f3a-b4d0-fcbcf64760ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "#Decision Tree\n",
        "import numpy as np\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "no_frauds = len(dataset[dataset['DepDel15']==1])\n",
        "non_fraud_indices = dataset[dataset.DepDel15 == 0].index\n",
        "random_indices = np.random.choice(non_fraud_indices,no_frauds, replace=False)\n",
        "fraud_indices = dataset[dataset.DepDel15 == 1].index\n",
        "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n",
        "under_sample = dataset.loc[under_sample_indices]\n",
        "dataset = under_sample\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:, [21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:, 7])\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "# Fitting Decision Tree Classification to the Training set\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.66      0.62     90957\n",
            "         1.0       0.61      0.54      0.57     90542\n",
            "\n",
            "    accuracy                           0.60    181499\n",
            "   macro avg       0.60      0.60      0.60    181499\n",
            "weighted avg       0.60      0.60      0.60    181499\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc6Yf_AwkpWd",
        "colab_type": "code",
        "outputId": "158c706f-bc9f-4664-cc68-6990c34354ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "#Extra trees using depdel15 and oversampling\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "no_frauds = len(dataset[dataset['DepDel15']==1])\n",
        "non_fraud_indices = dataset[dataset.DepDel15 == 0].index\n",
        "random_indices = np.random.choice(non_fraud_indices,no_frauds, replace=False)\n",
        "fraud_indices = dataset[dataset.DepDel15 == 1].index\n",
        "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n",
        "under_sample = dataset.loc[under_sample_indices]\n",
        "dataset = under_sample\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:, [21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:, 7])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "extc = ExtraTreesClassifier(n_estimators = 100+i,n_jobs = -1)\n",
        "extc.fit(X_train,y_train)\n",
        "\n",
        "y_pred = extc.predict(X_train)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "\n",
        "y_pred = extc.predict(X_test)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.83      0.78    290475\n",
            "         1.0       0.81      0.71      0.75    290320\n",
            "\n",
            "    accuracy                           0.77    580795\n",
            "   macro avg       0.77      0.77      0.77    580795\n",
            "weighted avg       0.77      0.77      0.77    580795\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.67      0.63     72522\n",
            "         1.0       0.62      0.54      0.58     72677\n",
            "\n",
            "    accuracy                           0.60    145199\n",
            "   macro avg       0.61      0.60      0.60    145199\n",
            "weighted avg       0.61      0.60      0.60    145199\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAKEudMck1El",
        "colab_type": "code",
        "outputId": "cdf3aabc-7f55-4e6c-c436-47a4331eddf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "# XGBoost on depdel15\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "no_frauds = len(dataset[dataset['DepDel15']==1])\n",
        "non_fraud_indices = dataset[dataset.DepDel15 == 0].index\n",
        "random_indices = np.random.choice(non_fraud_indices,no_frauds, replace=False)\n",
        "fraud_indices = dataset[dataset.DepDel15 == 1].index\n",
        "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n",
        "under_sample = dataset.loc[under_sample_indices]\n",
        "dataset = under_sample\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:, [21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:, 7])\n",
        "\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=0)\n",
        "\n",
        "# Fitting XGBoost to the Training set\n",
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_train)\n",
        "from sklearn.metrics import classification_report\n",
        "print('Training set')\n",
        "print(classification_report(y_pred,y_train))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print('Test set')\n",
        "print(classification_report(y_pred,y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.58      0.59    307498\n",
            "         1.0       0.55      0.59      0.57    273297\n",
            "\n",
            "    accuracy                           0.58    580795\n",
            "   macro avg       0.58      0.58      0.58    580795\n",
            "weighted avg       0.58      0.58      0.58    580795\n",
            "\n",
            "Test set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.58      0.59     76849\n",
            "         1.0       0.55      0.58      0.57     68350\n",
            "\n",
            "    accuracy                           0.58    145199\n",
            "   macro avg       0.58      0.58      0.58    145199\n",
            "weighted avg       0.58      0.58      0.58    145199\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crvc9S7sljy1",
        "colab_type": "text"
      },
      "source": [
        "#Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF65Ouiwk9pn",
        "colab_type": "code",
        "outputId": "79ac119d-bbfa-4bcb-ef0a-fab8fae92cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#Logistic Regression\n",
        "import numpy as np\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE()\n",
        "\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:,[21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:,7])\n",
        "\n",
        "\n",
        "#splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.25, random_state = 0)\n",
        "X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.59      0.69    363037\n",
            "         1.0       0.25      0.54      0.34     90814\n",
            "\n",
            "    accuracy                           0.58    453851\n",
            "   macro avg       0.54      0.57      0.52    453851\n",
            "weighted avg       0.72      0.58      0.62    453851\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wduBMV-CzXUY",
        "colab_type": "code",
        "outputId": "dada5f00-9b2d-4d69-df9c-ad6298d4ff4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "\n",
        "#Random_Forest  depdel15\n",
        "import numpy as np\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE()\n",
        "\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:,[21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:,7])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "print(\"N_estimators = \" + str(100))\n",
        "# Fitting Random Forest Classification to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 0, n_jobs = -1)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_train)\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "N_estimators = 100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.86      0.85   1162053\n",
            "         1.0       0.86      0.84      0.85   1162053\n",
            "\n",
            "    accuracy                           0.85   2324106\n",
            "   macro avg       0.85      0.85      0.85   2324106\n",
            "weighted avg       0.85      0.85      0.85   2324106\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.83      0.84    290352\n",
            "         1.0       0.36      0.38      0.37     72729\n",
            "\n",
            "    accuracy                           0.74    363081\n",
            "   macro avg       0.60      0.61      0.60    363081\n",
            "weighted avg       0.75      0.74      0.74    363081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7HUsJnIzkRg",
        "colab_type": "code",
        "outputId": "1c297fb5-3a3b-4be9-f9de-44a83bb01a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "#Decision Tree\n",
        "import numpy as np\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE()\n",
        "\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:,[21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:,7])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "\n",
        "# Fitting Decision Tree Classification to the Training set\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.85      0.84    290787\n",
            "         1.0       0.37      0.36      0.37     72294\n",
            "\n",
            "    accuracy                           0.75    363081\n",
            "   macro avg       0.60      0.60      0.60    363081\n",
            "weighted avg       0.75      0.75      0.75    363081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l85l4xIAzrog",
        "colab_type": "code",
        "outputId": "57ed1040-fe21-451f-ad69-1617dd6ee8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#Extra trees using depdel15 and oversampling\n",
        "import numpy as np\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE()\n",
        "\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:,[21,22,23,24,25,26,27,28,30,31]]\n",
        "y = pd.DataFrame(dataset.iloc[:,7])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 12)\n",
        "X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "extc = ExtraTreesClassifier(n_estimators = 200,n_jobs = -1)\n",
        "extc.fit(X_train,y_train)\n",
        "\n",
        "y_pred = extc.predict(X_train)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "\n",
        "y_pred = extc.predict(X_test)\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6fPCOs1zxT-",
        "colab_type": "code",
        "outputId": "fcd51cb9-b5df-4bba-fd3f-839dc9cf4058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "# XGBoost on depdel15\n",
        "\n",
        "# Importing the dataset\n",
        "import numpy as np\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE()\n",
        "\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:,[21,22,23,24,25,26,27,28,30,31]].values\n",
        "y = pd.DataFrame(dataset.iloc[:,7]).values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "# Fitting XGBoost to the Training set\n",
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_train)\n",
        "from sklearn.metrics import classification_report\n",
        "print('Training set')\n",
        "print(classification_report(y_pred,y_train))\n",
        "\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "from sklearn.metrics import classification_report\n",
        "print('Test set')\n",
        "print(classification_report(y_pred,y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.63      0.66   1268604\n",
            "         1.0       0.60      0.66      0.63   1054740\n",
            "\n",
            "    accuracy                           0.65   2323344\n",
            "   macro avg       0.65      0.65      0.65   2323344\n",
            "weighted avg       0.65      0.65      0.65   2323344\n",
            "\n",
            "Test set\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.69      0.83      0.76    242402\n",
            "         1.0       0.44      0.26      0.33    120679\n",
            "\n",
            "    accuracy                           0.64    363081\n",
            "   macro avg       0.57      0.55      0.54    363081\n",
            "weighted avg       0.61      0.64      0.62    363081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq78gW2DwcLH",
        "colab_type": "text"
      },
      "source": [
        "#Proper Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlAapyKBz2ev",
        "colab_type": "code",
        "outputId": "1abf878d-21e3-4370-e972-120cef095175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "dataset.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'ArrDel15', 'ArrDelayMinutes', 'ArrTime', 'CRSArrTime',\n",
              "       'CRSDepTime', 'DayofMonth', 'DepDel15', 'DepDelayMinutes', 'DepTime',\n",
              "       'Dest', 'DestAirportID', 'FlightDate', 'Month', 'Origin',\n",
              "       'OriginAirportID', 'Quarter', 'Year', 'CRSDepTimedup', 'CRSArrTimedup',\n",
              "       'airport_x', 'DewPointF_x', 'windspeedKmph_x', 'precipMM_x',\n",
              "       'WindGustKmph_x', 'tempF_x', 'WindChillF_x', 'winddirDegree_x',\n",
              "       'humidity_x', 'time_x', 'cloudcover_x', 'pressure_x', 'airport_y',\n",
              "       'DewPointF_y', 'windspeedKmph_y', 'precipMM_y', 'WindGustKmph_y',\n",
              "       'tempF_y', 'WindChillF_y', 'winddirDegree_y', 'humidity_y', 'time_y',\n",
              "       'cloudcover_y', 'pressure_y', 'FlightData'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWlIi9hks4xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_features = [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34,35,36,37,38,39,40,41,42,43]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mmx692ytp7G",
        "colab_type": "code",
        "outputId": "5442ed0e-bf9d-427f-bfcb-ce4118368267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "\n",
        "X = dataset.iloc[:,X_features]\n",
        "y = pd.DataFrame(dataset.iloc[:,7])\n",
        "X.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DewPointF_x', 'windspeedKmph_x', 'precipMM_x', 'WindGustKmph_x',\n",
              "       'tempF_x', 'WindChillF_x', 'winddirDegree_x', 'humidity_x', 'time_x',\n",
              "       'cloudcover_x', 'pressure_x', 'DewPointF_y', 'windspeedKmph_y',\n",
              "       'precipMM_y', 'WindGustKmph_y', 'tempF_y', 'WindChillF_y',\n",
              "       'winddirDegree_y', 'humidity_y', 'time_y', 'cloudcover_y',\n",
              "       'pressure_y'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cOpjt1vxR2W",
        "colab_type": "code",
        "outputId": "eb834d8c-6272-43de-bb24-11e201784ec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DepDel15'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lu39eBDwNJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDmjk0rlvh3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-LZkc7ovadP",
        "colab_type": "text"
      },
      "source": [
        "##Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdXVXnWWvXke",
        "colab_type": "code",
        "outputId": "f4da4cd5-54b1-4345-e2a5-bd2f01704691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "\n",
        "#sc_X = StandardScaler()\n",
        "#X_train = sc_X.fit_transform(X_train)\n",
        "#X_test = sc_X.transform(X_test)\n",
        "\n",
        "#splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      1.00      0.89   1161699\n",
            "         1.0       0.52      0.01      0.02    290622\n",
            "\n",
            "    accuracy                           0.80   1452321\n",
            "   macro avg       0.66      0.50      0.46   1452321\n",
            "weighted avg       0.75      0.80      0.72   1452321\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      1.00      0.89    290706\n",
            "         1.0       0.50      0.01      0.02     72375\n",
            "\n",
            "    accuracy                           0.80    363081\n",
            "   macro avg       0.65      0.50      0.46    363081\n",
            "weighted avg       0.74      0.80      0.72    363081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWi81CJjBQd4",
        "colab_type": "text"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLs0bfASvtJ9",
        "colab_type": "code",
        "outputId": "ab830eb1-329e-414c-c9ab-cad00021415c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "# Fitting Random Forest Classification to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0, n_jobs = -1)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.99      0.98   1161699\n",
            "         1.0       0.96      0.87      0.91    290622\n",
            "\n",
            "    accuracy                           0.97   1452321\n",
            "   macro avg       0.96      0.93      0.95   1452321\n",
            "weighted avg       0.97      0.97      0.97   1452321\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.94      0.88    290706\n",
            "         1.0       0.46      0.20      0.28     72375\n",
            "\n",
            "    accuracy                           0.79    363081\n",
            "   macro avg       0.65      0.57      0.58    363081\n",
            "weighted avg       0.75      0.79      0.76    363081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNjzgXAxBpT9",
        "colab_type": "text"
      },
      "source": [
        "##Extra trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mnG7nFSxiKm",
        "colab_type": "code",
        "outputId": "528685db-77db-496d-f7eb-38d906ab7957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "classifier = ExtraTreesClassifier(n_estimators = 100,n_jobs = -1)\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      1.00      0.98   1161699\n",
            "         1.0       0.99      0.84      0.91    290622\n",
            "\n",
            "    accuracy                           0.97   1452321\n",
            "   macro avg       0.98      0.92      0.95   1452321\n",
            "weighted avg       0.97      0.97      0.97   1452321\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.94      0.88    290706\n",
            "         1.0       0.45      0.20      0.28     72375\n",
            "\n",
            "    accuracy                           0.79    363081\n",
            "   macro avg       0.64      0.57      0.58    363081\n",
            "weighted avg       0.75      0.79      0.76    363081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwgWb2E_B8dc",
        "colab_type": "text"
      },
      "source": [
        "##XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOaCbxOlBy0i",
        "colab_type": "code",
        "outputId": "0a020898-8fdd-4be5-db35-ff830a9c3b11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "\n",
        "#splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)# Fitting XGBoost to the Training set\n",
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      1.00      0.89   1161699\n",
            "         1.0       0.66      0.02      0.04    290622\n",
            "\n",
            "    accuracy                           0.80   1452321\n",
            "   macro avg       0.73      0.51      0.46   1452321\n",
            "weighted avg       0.77      0.80      0.72   1452321\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.80      1.00      0.89    290706\n",
            "         1.0       0.67      0.02      0.04     72375\n",
            "\n",
            "    accuracy                           0.80    363081\n",
            "   macro avg       0.74      0.51      0.46    363081\n",
            "weighted avg       0.78      0.80      0.72    363081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glxb_el2Ktkw",
        "colab_type": "text"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvIdi_HJB_Ug",
        "colab_type": "code",
        "outputId": "7d7af0d0-3b6d-429a-9c57-cd846361af59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      1.00      0.98   1161699\n",
            "         1.0       0.99      0.84      0.91    290622\n",
            "\n",
            "    accuracy                           0.97   1452321\n",
            "   macro avg       0.98      0.92      0.95   1452321\n",
            "weighted avg       0.97      0.97      0.97   1452321\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.84      0.83    290706\n",
            "         1.0       0.32      0.31      0.32     72375\n",
            "\n",
            "    accuracy                           0.73    363081\n",
            "   macro avg       0.58      0.57      0.57    363081\n",
            "weighted avg       0.73      0.73      0.73    363081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72dRK8T7K3sQ",
        "colab_type": "text"
      },
      "source": [
        "#Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXI2a6gIK1m8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "no_frauds = len(dataset[dataset['ArrDel15']==1])\n",
        "non_fraud_indices = dataset[dataset.DepDel15 == 0].index\n",
        "random_indices = np.random.choice(non_fraud_indices,no_frauds, replace=False)\n",
        "fraud_indices = dataset[dataset.DepDel15 == 1].index\n",
        "under_sample_indices = np.concatenate([fraud_indices,random_indices])\n",
        "under_sample = dataset.loc[under_sample_indices]\n",
        "dataset = under_sample\n",
        "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
        "X = dataset.iloc[:,X_features]\n",
        "y = pd.DataFrame(dataset.iloc[:,7])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oBdeyzXLHAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzcIIXeaLLSH",
        "colab_type": "text"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3KZNx26LKYQ",
        "colab_type": "code",
        "outputId": "8ee08497-f244-4a50-aad1-bf9f22d9eb36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.61      0.61    303689\n",
            "         1.0       0.59      0.60      0.59    290201\n",
            "\n",
            "    accuracy                           0.60    593890\n",
            "   macro avg       0.60      0.60      0.60    593890\n",
            "weighted avg       0.60      0.60      0.60    593890\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.61      0.61     75677\n",
            "         1.0       0.59      0.60      0.60     72796\n",
            "\n",
            "    accuracy                           0.60    148473\n",
            "   macro avg       0.60      0.60      0.60    148473\n",
            "weighted avg       0.60      0.60      0.60    148473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTtoMQU7LSgu",
        "colab_type": "text"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn0HilwZLRVf",
        "colab_type": "code",
        "outputId": "5d24a690-cec2-4974-a495-f3e3ae438429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 0, n_jobs = -1)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.99      0.98   1161699\n",
            "         1.0       0.97      0.87      0.91    290622\n",
            "\n",
            "    accuracy                           0.97   1452321\n",
            "   macro avg       0.97      0.93      0.95   1452321\n",
            "weighted avg       0.97      0.97      0.97   1452321\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.94      0.88    290706\n",
            "         1.0       0.47      0.20      0.28     72375\n",
            "\n",
            "    accuracy                           0.80    363081\n",
            "   macro avg       0.65      0.57      0.58    363081\n",
            "weighted avg       0.75      0.80      0.76    363081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NQ9ZbQ_Wz5N",
        "colab_type": "text"
      },
      "source": [
        "##Extra Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMeXm3adLXZe",
        "colab_type": "code",
        "outputId": "71a6e51d-55ce-4dcc-933d-ae9288f21a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "classifier = ExtraTreesClassifier(n_estimators = 100,n_jobs = -1)\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      1.00      0.98    303689\n",
            "         1.0       1.00      0.96      0.98    290201\n",
            "\n",
            "    accuracy                           0.98    593890\n",
            "   macro avg       0.98      0.98      0.98    593890\n",
            "weighted avg       0.98      0.98      0.98    593890\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.64      0.68      0.66     75677\n",
            "         1.0       0.64      0.60      0.62     72796\n",
            "\n",
            "    accuracy                           0.64    148473\n",
            "   macro avg       0.64      0.64      0.64    148473\n",
            "weighted avg       0.64      0.64      0.64    148473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1j2czQNYnR2",
        "colab_type": "text"
      },
      "source": [
        "##XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz-09973W7rN",
        "colab_type": "code",
        "outputId": "92fd825a-ef6b-4965-c332-41dd6faba491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "\n",
        "#splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)# Fitting XGBoost to the Training set\n",
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.63      0.63    303689\n",
            "         1.0       0.61      0.61      0.61    290201\n",
            "\n",
            "    accuracy                           0.62    593890\n",
            "   macro avg       0.62      0.62      0.62    593890\n",
            "weighted avg       0.62      0.62      0.62    593890\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.62      0.63      0.63     75677\n",
            "         1.0       0.61      0.61      0.61     72796\n",
            "\n",
            "    accuracy                           0.62    148473\n",
            "   macro avg       0.62      0.62      0.62    148473\n",
            "weighted avg       0.62      0.62      0.62    148473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48DA2L4PY2jF",
        "colab_type": "text"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1B1U0V7Yq_D",
        "colab_type": "code",
        "outputId": "0471e5d2-aa39-4e4d-fa0c-d9550f8a84aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      1.00      0.98    303689\n",
            "         1.0       1.00      0.96      0.98    290201\n",
            "\n",
            "    accuracy                           0.98    593890\n",
            "   macro avg       0.98      0.98      0.98    593890\n",
            "weighted avg       0.98      0.98      0.98    593890\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.59      0.59      0.59     75677\n",
            "         1.0       0.57      0.56      0.57     72796\n",
            "\n",
            "    accuracy                           0.58    148473\n",
            "   macro avg       0.58      0.58      0.58    148473\n",
            "weighted avg       0.58      0.58      0.58    148473\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVxgs099ZGE-",
        "colab_type": "text"
      },
      "source": [
        "#Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHGa62rkY3zJ",
        "colab_type": "code",
        "outputId": "c63e059a-d5c6-47f9-cf30-4e5d30fc27fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import numpy as np\n",
        "dataset = pd.read_csv('final_dataset.csv')\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE()\n",
        "\n",
        "\n",
        "X = dataset.iloc[:,X_features].values\n",
        "y = pd.DataFrame(dataset.iloc[:,7]).values\n",
        "X,y = sm.fit_sample(X_train,y_train)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2X9lJKZZl44",
        "colab_type": "text"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05LJu3FpZSQU",
        "colab_type": "code",
        "outputId": "02a46894-e04f-428f-9b7d-81b7bee0a381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "#X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.58      0.60    929381\n",
            "         1.0       0.60      0.63      0.62    929337\n",
            "\n",
            "    accuracy                           0.61   1858718\n",
            "   macro avg       0.61      0.61      0.61   1858718\n",
            "weighted avg       0.61      0.61      0.61   1858718\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.58      0.60    232318\n",
            "         1.0       0.60      0.63      0.62    232362\n",
            "\n",
            "    accuracy                           0.61    464680\n",
            "   macro avg       0.61      0.61      0.61    464680\n",
            "weighted avg       0.61      0.61      0.61    464680\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMUUGmA3ZwYf",
        "colab_type": "text"
      },
      "source": [
        "##Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuOIENpIZpv9",
        "colab_type": "code",
        "outputId": "a5fe1e96-6cb2-4a61-ddfa-a7a7ab349001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "#X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      1.00      0.98    929381\n",
            "         1.0       1.00      0.97      0.98    929337\n",
            "\n",
            "    accuracy                           0.98   1858718\n",
            "   macro avg       0.98      0.98      0.98   1858718\n",
            "weighted avg       0.98      0.98      0.98   1858718\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.82      0.82    232318\n",
            "         1.0       0.82      0.82      0.82    232362\n",
            "\n",
            "    accuracy                           0.82    464680\n",
            "   macro avg       0.82      0.82      0.82    464680\n",
            "weighted avg       0.82      0.82      0.82    464680\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsVDeonKZ7Jt",
        "colab_type": "text"
      },
      "source": [
        "##Extra Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQq4X9kWZ8Pt",
        "colab_type": "code",
        "outputId": "c586b188-87cd-4a76-a4d3-76b869cc45a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "#X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "classifier = ExtraTreesClassifier(n_estimators = 200,n_jobs = -1)\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3WLH0ILaDoj",
        "colab_type": "text"
      },
      "source": [
        "##XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHk-TBDHaAEe",
        "colab_type": "code",
        "outputId": "f51cbb8f-3114-4366-e7e0-e262ca4d9169",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "#X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.83      0.78    929381\n",
            "         1.0       0.81      0.71      0.76    929337\n",
            "\n",
            "    accuracy                           0.77   1858718\n",
            "   macro avg       0.78      0.77      0.77   1858718\n",
            "weighted avg       0.78      0.77      0.77   1858718\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.83      0.78    232318\n",
            "         1.0       0.81      0.71      0.76    232362\n",
            "\n",
            "    accuracy                           0.77    464680\n",
            "   macro avg       0.78      0.77      0.77    464680\n",
            "weighted avg       0.78      0.77      0.77    464680\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2toEmxPDaIg1",
        "colab_type": "text"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEM7bS3YaJvf",
        "colab_type": "code",
        "outputId": "306daaac-a0ff-4ed9-dbfe-acde8709013c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12)\n",
        "X_train,y_train = sm.fit_sample(X_train,y_train)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0, n_jobs = -1)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "print(\"Train\")\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "print(classification_report(y_train,y_pred))\n",
        "\n",
        "print(\"Test\")\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.98    929381\n",
            "         1.0       0.99      0.98      0.98    929381\n",
            "\n",
            "    accuracy                           0.98   1858762\n",
            "   macro avg       0.98      0.98      0.98   1858762\n",
            "weighted avg       0.98      0.98      0.98   1858762\n",
            "\n",
            "Test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.91      0.87    232318\n",
            "         1.0       0.91      0.82      0.86    232362\n",
            "\n",
            "    accuracy                           0.87    464680\n",
            "   macro avg       0.87      0.87      0.87    464680\n",
            "weighted avg       0.87      0.87      0.87    464680\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umA6sbjYcd6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}